{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9994815966822186,
  "eval_steps": 500,
  "global_step": 3615,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.041472265422498704,
      "grad_norm": 0.5669493675231934,
      "learning_rate": 4.930843706777317e-05,
      "loss": 2.8863,
      "step": 50
    },
    {
      "epoch": 0.08294453084499741,
      "grad_norm": 0.6545544862747192,
      "learning_rate": 4.861687413554633e-05,
      "loss": 2.6273,
      "step": 100
    },
    {
      "epoch": 0.12441679626749612,
      "grad_norm": 0.6281373500823975,
      "learning_rate": 4.792531120331951e-05,
      "loss": 2.5375,
      "step": 150
    },
    {
      "epoch": 0.16588906168999482,
      "grad_norm": 0.9093654155731201,
      "learning_rate": 4.723374827109267e-05,
      "loss": 2.422,
      "step": 200
    },
    {
      "epoch": 0.20736132711249353,
      "grad_norm": 0.9158812761306763,
      "learning_rate": 4.654218533886584e-05,
      "loss": 2.4132,
      "step": 250
    },
    {
      "epoch": 0.24883359253499224,
      "grad_norm": 0.8073300719261169,
      "learning_rate": 4.5850622406639e-05,
      "loss": 2.3704,
      "step": 300
    },
    {
      "epoch": 0.2903058579574909,
      "grad_norm": 0.8337472081184387,
      "learning_rate": 4.515905947441218e-05,
      "loss": 2.3744,
      "step": 350
    },
    {
      "epoch": 0.33177812337998963,
      "grad_norm": 1.0627777576446533,
      "learning_rate": 4.446749654218534e-05,
      "loss": 2.3658,
      "step": 400
    },
    {
      "epoch": 0.37325038880248834,
      "grad_norm": 1.023947834968567,
      "learning_rate": 4.377593360995851e-05,
      "loss": 2.334,
      "step": 450
    },
    {
      "epoch": 0.41472265422498705,
      "grad_norm": 1.0902271270751953,
      "learning_rate": 4.3084370677731676e-05,
      "loss": 2.3416,
      "step": 500
    },
    {
      "epoch": 0.45619491964748576,
      "grad_norm": 1.0423208475112915,
      "learning_rate": 4.2392807745504845e-05,
      "loss": 2.3209,
      "step": 550
    },
    {
      "epoch": 0.4976671850699845,
      "grad_norm": 1.0269778966903687,
      "learning_rate": 4.1701244813278014e-05,
      "loss": 2.3288,
      "step": 600
    },
    {
      "epoch": 0.5391394504924831,
      "grad_norm": 1.0664278268814087,
      "learning_rate": 4.1009681881051176e-05,
      "loss": 2.2763,
      "step": 650
    },
    {
      "epoch": 0.5806117159149818,
      "grad_norm": 1.0770156383514404,
      "learning_rate": 4.0318118948824344e-05,
      "loss": 2.2841,
      "step": 700
    },
    {
      "epoch": 0.6220839813374806,
      "grad_norm": 1.0170302391052246,
      "learning_rate": 3.962655601659751e-05,
      "loss": 2.3021,
      "step": 750
    },
    {
      "epoch": 0.6635562467599793,
      "grad_norm": 1.2005621194839478,
      "learning_rate": 3.893499308437068e-05,
      "loss": 2.3128,
      "step": 800
    },
    {
      "epoch": 0.705028512182478,
      "grad_norm": 1.2597404718399048,
      "learning_rate": 3.8243430152143844e-05,
      "loss": 2.3012,
      "step": 850
    },
    {
      "epoch": 0.7465007776049767,
      "grad_norm": 1.1664166450500488,
      "learning_rate": 3.755186721991701e-05,
      "loss": 2.3034,
      "step": 900
    },
    {
      "epoch": 0.7879730430274754,
      "grad_norm": 1.3229931592941284,
      "learning_rate": 3.686030428769018e-05,
      "loss": 2.2751,
      "step": 950
    },
    {
      "epoch": 0.8294453084499741,
      "grad_norm": 1.1805421113967896,
      "learning_rate": 3.616874135546335e-05,
      "loss": 2.2762,
      "step": 1000
    },
    {
      "epoch": 0.8709175738724728,
      "grad_norm": 1.2950855493545532,
      "learning_rate": 3.547717842323652e-05,
      "loss": 2.2785,
      "step": 1050
    },
    {
      "epoch": 0.9123898392949715,
      "grad_norm": 1.237825870513916,
      "learning_rate": 3.478561549100968e-05,
      "loss": 2.2764,
      "step": 1100
    },
    {
      "epoch": 0.9538621047174702,
      "grad_norm": 1.2363853454589844,
      "learning_rate": 3.409405255878285e-05,
      "loss": 2.2815,
      "step": 1150
    },
    {
      "epoch": 0.995334370139969,
      "grad_norm": 1.1434341669082642,
      "learning_rate": 3.340248962655602e-05,
      "loss": 2.2863,
      "step": 1200
    },
    {
      "epoch": 0.9994815966822188,
      "eval_loss": 2.2542638778686523,
      "eval_runtime": 51.9114,
      "eval_samples_per_second": 41.301,
      "eval_steps_per_second": 5.163,
      "step": 1205
    },
    {
      "epoch": 1.0373250388802489,
      "grad_norm": 1.4413731098175049,
      "learning_rate": 3.271092669432919e-05,
      "loss": 2.2796,
      "step": 1250
    },
    {
      "epoch": 1.0787973043027475,
      "grad_norm": 0.9932212829589844,
      "learning_rate": 3.201936376210235e-05,
      "loss": 2.2713,
      "step": 1300
    },
    {
      "epoch": 1.1202695697252463,
      "grad_norm": 1.5249725580215454,
      "learning_rate": 3.132780082987552e-05,
      "loss": 2.2479,
      "step": 1350
    },
    {
      "epoch": 1.1617418351477449,
      "grad_norm": 1.2550015449523926,
      "learning_rate": 3.063623789764869e-05,
      "loss": 2.2169,
      "step": 1400
    },
    {
      "epoch": 1.2032141005702437,
      "grad_norm": 1.3287911415100098,
      "learning_rate": 2.9944674965421855e-05,
      "loss": 2.2514,
      "step": 1450
    },
    {
      "epoch": 1.2446863659927423,
      "grad_norm": 1.3689202070236206,
      "learning_rate": 2.9253112033195024e-05,
      "loss": 2.2299,
      "step": 1500
    },
    {
      "epoch": 1.2861586314152411,
      "grad_norm": 1.494531512260437,
      "learning_rate": 2.856154910096819e-05,
      "loss": 2.2352,
      "step": 1550
    },
    {
      "epoch": 1.3276308968377397,
      "grad_norm": 1.5064607858657837,
      "learning_rate": 2.7869986168741358e-05,
      "loss": 2.2514,
      "step": 1600
    },
    {
      "epoch": 1.3691031622602385,
      "grad_norm": 1.7653675079345703,
      "learning_rate": 2.7178423236514523e-05,
      "loss": 2.2026,
      "step": 1650
    },
    {
      "epoch": 1.4105754276827371,
      "grad_norm": 1.3622212409973145,
      "learning_rate": 2.6486860304287692e-05,
      "loss": 2.2093,
      "step": 1700
    },
    {
      "epoch": 1.4520476931052357,
      "grad_norm": 1.4511048793792725,
      "learning_rate": 2.579529737206086e-05,
      "loss": 2.2271,
      "step": 1750
    },
    {
      "epoch": 1.4935199585277346,
      "grad_norm": 1.408476710319519,
      "learning_rate": 2.5103734439834026e-05,
      "loss": 2.2561,
      "step": 1800
    },
    {
      "epoch": 1.5349922239502334,
      "grad_norm": 1.5011132955551147,
      "learning_rate": 2.441217150760719e-05,
      "loss": 2.1747,
      "step": 1850
    },
    {
      "epoch": 1.576464489372732,
      "grad_norm": 1.6587398052215576,
      "learning_rate": 2.372060857538036e-05,
      "loss": 2.2149,
      "step": 1900
    },
    {
      "epoch": 1.6179367547952306,
      "grad_norm": 1.3071861267089844,
      "learning_rate": 2.3029045643153525e-05,
      "loss": 2.2581,
      "step": 1950
    },
    {
      "epoch": 1.6594090202177294,
      "grad_norm": 1.7902063131332397,
      "learning_rate": 2.2337482710926697e-05,
      "loss": 2.2216,
      "step": 2000
    },
    {
      "epoch": 1.7008812856402282,
      "grad_norm": 1.4482260942459106,
      "learning_rate": 2.1645919778699863e-05,
      "loss": 2.2336,
      "step": 2050
    },
    {
      "epoch": 1.7423535510627268,
      "grad_norm": 1.5997867584228516,
      "learning_rate": 2.095435684647303e-05,
      "loss": 2.1849,
      "step": 2100
    },
    {
      "epoch": 1.7838258164852254,
      "grad_norm": 1.6635764837265015,
      "learning_rate": 2.0262793914246197e-05,
      "loss": 2.229,
      "step": 2150
    },
    {
      "epoch": 1.8252980819077242,
      "grad_norm": 1.3542265892028809,
      "learning_rate": 1.9571230982019366e-05,
      "loss": 2.2217,
      "step": 2200
    },
    {
      "epoch": 1.866770347330223,
      "grad_norm": 1.3842556476593018,
      "learning_rate": 1.887966804979253e-05,
      "loss": 2.2299,
      "step": 2250
    },
    {
      "epoch": 1.9082426127527217,
      "grad_norm": 1.3779617547988892,
      "learning_rate": 1.81881051175657e-05,
      "loss": 2.2218,
      "step": 2300
    },
    {
      "epoch": 1.9497148781752203,
      "grad_norm": 1.5276228189468384,
      "learning_rate": 1.7496542185338865e-05,
      "loss": 2.2301,
      "step": 2350
    },
    {
      "epoch": 1.991187143597719,
      "grad_norm": 1.5326552391052246,
      "learning_rate": 1.6804979253112034e-05,
      "loss": 2.1577,
      "step": 2400
    },
    {
      "epoch": 1.9994815966822188,
      "eval_loss": 2.205803871154785,
      "eval_runtime": 52.1238,
      "eval_samples_per_second": 41.133,
      "eval_steps_per_second": 5.142,
      "step": 2410
    },
    {
      "epoch": 2.033177812337999,
      "grad_norm": 1.3224998712539673,
      "learning_rate": 1.6113416320885202e-05,
      "loss": 2.2765,
      "step": 2450
    },
    {
      "epoch": 2.0746500777604977,
      "grad_norm": 1.4268267154693604,
      "learning_rate": 1.5421853388658368e-05,
      "loss": 2.2191,
      "step": 2500
    },
    {
      "epoch": 2.1161223431829965,
      "grad_norm": 1.8215876817703247,
      "learning_rate": 1.4730290456431537e-05,
      "loss": 2.2736,
      "step": 2550
    },
    {
      "epoch": 2.157594608605495,
      "grad_norm": 1.6607391834259033,
      "learning_rate": 1.4038727524204704e-05,
      "loss": 2.2077,
      "step": 2600
    },
    {
      "epoch": 2.1990668740279937,
      "grad_norm": 1.6389437913894653,
      "learning_rate": 1.334716459197787e-05,
      "loss": 2.1889,
      "step": 2650
    },
    {
      "epoch": 2.2405391394504925,
      "grad_norm": 1.5206458568572998,
      "learning_rate": 1.2655601659751038e-05,
      "loss": 2.2019,
      "step": 2700
    },
    {
      "epoch": 2.2820114048729914,
      "grad_norm": 1.4870219230651855,
      "learning_rate": 1.1964038727524206e-05,
      "loss": 2.1662,
      "step": 2750
    },
    {
      "epoch": 2.3234836702954897,
      "grad_norm": 1.6259398460388184,
      "learning_rate": 1.1272475795297373e-05,
      "loss": 2.2053,
      "step": 2800
    },
    {
      "epoch": 2.3649559357179886,
      "grad_norm": 1.642920970916748,
      "learning_rate": 1.058091286307054e-05,
      "loss": 2.1948,
      "step": 2850
    },
    {
      "epoch": 2.4064282011404874,
      "grad_norm": 1.3917970657348633,
      "learning_rate": 9.889349930843707e-06,
      "loss": 2.1807,
      "step": 2900
    },
    {
      "epoch": 2.447900466562986,
      "grad_norm": 1.8829469680786133,
      "learning_rate": 9.197786998616875e-06,
      "loss": 2.2196,
      "step": 2950
    },
    {
      "epoch": 2.4893727319854846,
      "grad_norm": 1.5872126817703247,
      "learning_rate": 8.506224066390042e-06,
      "loss": 2.1951,
      "step": 3000
    },
    {
      "epoch": 2.5308449974079834,
      "grad_norm": 1.5165321826934814,
      "learning_rate": 7.814661134163209e-06,
      "loss": 2.1741,
      "step": 3050
    },
    {
      "epoch": 2.5723172628304822,
      "grad_norm": 1.7365412712097168,
      "learning_rate": 7.1230982019363765e-06,
      "loss": 2.1917,
      "step": 3100
    },
    {
      "epoch": 2.6137895282529806,
      "grad_norm": 1.6603978872299194,
      "learning_rate": 6.4315352697095435e-06,
      "loss": 2.1908,
      "step": 3150
    },
    {
      "epoch": 2.6552617936754794,
      "grad_norm": 1.531159520149231,
      "learning_rate": 5.7399723374827105e-06,
      "loss": 2.1842,
      "step": 3200
    },
    {
      "epoch": 2.6967340590979783,
      "grad_norm": 1.6938964128494263,
      "learning_rate": 5.0484094052558784e-06,
      "loss": 2.1695,
      "step": 3250
    },
    {
      "epoch": 2.738206324520477,
      "grad_norm": 1.3361221551895142,
      "learning_rate": 4.3568464730290455e-06,
      "loss": 2.1845,
      "step": 3300
    },
    {
      "epoch": 2.779678589942976,
      "grad_norm": 1.6385012865066528,
      "learning_rate": 3.6652835408022133e-06,
      "loss": 2.1748,
      "step": 3350
    },
    {
      "epoch": 2.8211508553654743,
      "grad_norm": 1.6483546495437622,
      "learning_rate": 2.9737206085753804e-06,
      "loss": 2.1614,
      "step": 3400
    },
    {
      "epoch": 2.862623120787973,
      "grad_norm": 1.5692497491836548,
      "learning_rate": 2.282157676348548e-06,
      "loss": 2.1591,
      "step": 3450
    },
    {
      "epoch": 2.9040953862104715,
      "grad_norm": 1.9526393413543701,
      "learning_rate": 1.590594744121715e-06,
      "loss": 2.1535,
      "step": 3500
    },
    {
      "epoch": 2.9455676516329703,
      "grad_norm": 1.6192798614501953,
      "learning_rate": 8.990318118948824e-07,
      "loss": 2.1678,
      "step": 3550
    },
    {
      "epoch": 2.987039917055469,
      "grad_norm": 1.7040811777114868,
      "learning_rate": 2.074688796680498e-07,
      "loss": 2.1922,
      "step": 3600
    },
    {
      "epoch": 2.9994815966822186,
      "eval_loss": 2.192274808883667,
      "eval_runtime": 51.9256,
      "eval_samples_per_second": 41.29,
      "eval_steps_per_second": 5.161,
      "step": 3615
    }
  ],
  "logging_steps": 50,
  "max_steps": 3615,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5396179197158400.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
