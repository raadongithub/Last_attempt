{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9994815966822186,
  "eval_steps": 500,
  "global_step": 3615,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.041472265422498704,
      "grad_norm": 0.5809592008590698,
      "learning_rate": 4.932226832641771e-05,
      "loss": 2.8854,
      "step": 50
    },
    {
      "epoch": 0.08294453084499741,
      "grad_norm": 0.6697035431861877,
      "learning_rate": 4.8630705394190874e-05,
      "loss": 2.6279,
      "step": 100
    },
    {
      "epoch": 0.12441679626749612,
      "grad_norm": 0.6377636194229126,
      "learning_rate": 4.793914246196404e-05,
      "loss": 2.5358,
      "step": 150
    },
    {
      "epoch": 0.16588906168999482,
      "grad_norm": 0.9169598817825317,
      "learning_rate": 4.7247579529737204e-05,
      "loss": 2.4202,
      "step": 200
    },
    {
      "epoch": 0.20736132711249353,
      "grad_norm": 0.9329835772514343,
      "learning_rate": 4.655601659751038e-05,
      "loss": 2.4119,
      "step": 250
    },
    {
      "epoch": 0.24883359253499224,
      "grad_norm": 0.8183119297027588,
      "learning_rate": 4.586445366528354e-05,
      "loss": 2.3695,
      "step": 300
    },
    {
      "epoch": 0.2903058579574909,
      "grad_norm": 0.8457039594650269,
      "learning_rate": 4.517289073305671e-05,
      "loss": 2.3731,
      "step": 350
    },
    {
      "epoch": 0.33177812337998963,
      "grad_norm": 1.0700610876083374,
      "learning_rate": 4.448132780082987e-05,
      "loss": 2.366,
      "step": 400
    },
    {
      "epoch": 0.37325038880248834,
      "grad_norm": 1.0347192287445068,
      "learning_rate": 4.378976486860305e-05,
      "loss": 2.3345,
      "step": 450
    },
    {
      "epoch": 0.41472265422498705,
      "grad_norm": 1.1043345928192139,
      "learning_rate": 4.309820193637622e-05,
      "loss": 2.341,
      "step": 500
    },
    {
      "epoch": 0.45619491964748576,
      "grad_norm": 1.0495500564575195,
      "learning_rate": 4.240663900414938e-05,
      "loss": 2.32,
      "step": 550
    },
    {
      "epoch": 0.4976671850699845,
      "grad_norm": 1.0272525548934937,
      "learning_rate": 4.171507607192255e-05,
      "loss": 2.3282,
      "step": 600
    },
    {
      "epoch": 0.5391394504924831,
      "grad_norm": 1.078452706336975,
      "learning_rate": 4.102351313969571e-05,
      "loss": 2.2758,
      "step": 650
    },
    {
      "epoch": 0.5806117159149818,
      "grad_norm": 1.0846186876296997,
      "learning_rate": 4.0331950207468885e-05,
      "loss": 2.284,
      "step": 700
    },
    {
      "epoch": 0.6220839813374806,
      "grad_norm": 1.0267579555511475,
      "learning_rate": 3.964038727524205e-05,
      "loss": 2.3028,
      "step": 750
    },
    {
      "epoch": 0.6635562467599793,
      "grad_norm": 1.206338882446289,
      "learning_rate": 3.8948824343015216e-05,
      "loss": 2.3125,
      "step": 800
    },
    {
      "epoch": 0.705028512182478,
      "grad_norm": 1.2561907768249512,
      "learning_rate": 3.825726141078838e-05,
      "loss": 2.3011,
      "step": 850
    },
    {
      "epoch": 0.7465007776049767,
      "grad_norm": 1.1792067289352417,
      "learning_rate": 3.756569847856155e-05,
      "loss": 2.3033,
      "step": 900
    },
    {
      "epoch": 0.7879730430274754,
      "grad_norm": 1.3312841653823853,
      "learning_rate": 3.687413554633472e-05,
      "loss": 2.2747,
      "step": 950
    },
    {
      "epoch": 0.8294453084499741,
      "grad_norm": 1.1686315536499023,
      "learning_rate": 3.6182572614107884e-05,
      "loss": 2.2762,
      "step": 1000
    },
    {
      "epoch": 0.8709175738724728,
      "grad_norm": 1.309641718864441,
      "learning_rate": 3.549100968188105e-05,
      "loss": 2.278,
      "step": 1050
    },
    {
      "epoch": 0.9123898392949715,
      "grad_norm": 1.2368624210357666,
      "learning_rate": 3.479944674965422e-05,
      "loss": 2.2756,
      "step": 1100
    },
    {
      "epoch": 0.9538621047174702,
      "grad_norm": 1.2262755632400513,
      "learning_rate": 3.410788381742739e-05,
      "loss": 2.2807,
      "step": 1150
    },
    {
      "epoch": 0.995334370139969,
      "grad_norm": 1.140794038772583,
      "learning_rate": 3.341632088520055e-05,
      "loss": 2.287,
      "step": 1200
    },
    {
      "epoch": 0.9994815966822188,
      "eval_loss": 2.254227876663208,
      "eval_runtime": 51.0993,
      "eval_samples_per_second": 41.958,
      "eval_steps_per_second": 5.245,
      "step": 1205
    },
    {
      "epoch": 1.0373250388802489,
      "grad_norm": 1.4560914039611816,
      "learning_rate": 3.272475795297372e-05,
      "loss": 2.2804,
      "step": 1250
    },
    {
      "epoch": 1.0787973043027475,
      "grad_norm": 0.9947916269302368,
      "learning_rate": 3.203319502074689e-05,
      "loss": 2.2716,
      "step": 1300
    },
    {
      "epoch": 1.1202695697252463,
      "grad_norm": 1.5184032917022705,
      "learning_rate": 3.134163208852006e-05,
      "loss": 2.2481,
      "step": 1350
    },
    {
      "epoch": 1.1617418351477449,
      "grad_norm": 1.2594051361083984,
      "learning_rate": 3.065006915629323e-05,
      "loss": 2.2167,
      "step": 1400
    },
    {
      "epoch": 1.2032141005702437,
      "grad_norm": 1.331413984298706,
      "learning_rate": 2.995850622406639e-05,
      "loss": 2.2515,
      "step": 1450
    },
    {
      "epoch": 1.2446863659927423,
      "grad_norm": 1.3618131875991821,
      "learning_rate": 2.926694329183956e-05,
      "loss": 2.2303,
      "step": 1500
    },
    {
      "epoch": 1.2861586314152411,
      "grad_norm": 1.5077323913574219,
      "learning_rate": 2.8575380359612723e-05,
      "loss": 2.2359,
      "step": 1550
    },
    {
      "epoch": 1.3276308968377397,
      "grad_norm": 1.498534083366394,
      "learning_rate": 2.7883817427385895e-05,
      "loss": 2.2519,
      "step": 1600
    },
    {
      "epoch": 1.3691031622602385,
      "grad_norm": 1.7218949794769287,
      "learning_rate": 2.7192254495159057e-05,
      "loss": 2.2022,
      "step": 1650
    },
    {
      "epoch": 1.4105754276827371,
      "grad_norm": 1.3789340257644653,
      "learning_rate": 2.650069156293223e-05,
      "loss": 2.2096,
      "step": 1700
    },
    {
      "epoch": 1.4520476931052357,
      "grad_norm": 1.4332889318466187,
      "learning_rate": 2.5809128630705398e-05,
      "loss": 2.2278,
      "step": 1750
    },
    {
      "epoch": 1.4935199585277346,
      "grad_norm": 1.4190764427185059,
      "learning_rate": 2.5117565698478563e-05,
      "loss": 2.2562,
      "step": 1800
    },
    {
      "epoch": 1.5349922239502334,
      "grad_norm": 1.5007836818695068,
      "learning_rate": 2.442600276625173e-05,
      "loss": 2.1757,
      "step": 1850
    },
    {
      "epoch": 1.576464489372732,
      "grad_norm": 1.6432585716247559,
      "learning_rate": 2.3734439834024897e-05,
      "loss": 2.2144,
      "step": 1900
    },
    {
      "epoch": 1.6179367547952306,
      "grad_norm": 1.3184257745742798,
      "learning_rate": 2.3042876901798063e-05,
      "loss": 2.2582,
      "step": 1950
    },
    {
      "epoch": 1.6594090202177294,
      "grad_norm": 1.8165347576141357,
      "learning_rate": 2.2351313969571235e-05,
      "loss": 2.2218,
      "step": 2000
    },
    {
      "epoch": 1.7008812856402282,
      "grad_norm": 1.4688024520874023,
      "learning_rate": 2.16597510373444e-05,
      "loss": 2.2333,
      "step": 2050
    },
    {
      "epoch": 1.7423535510627268,
      "grad_norm": 1.5979900360107422,
      "learning_rate": 2.096818810511757e-05,
      "loss": 2.1863,
      "step": 2100
    },
    {
      "epoch": 1.7838258164852254,
      "grad_norm": 1.6547327041625977,
      "learning_rate": 2.0276625172890734e-05,
      "loss": 2.2293,
      "step": 2150
    },
    {
      "epoch": 1.8252980819077242,
      "grad_norm": 1.3464412689208984,
      "learning_rate": 1.95850622406639e-05,
      "loss": 2.2215,
      "step": 2200
    },
    {
      "epoch": 1.866770347330223,
      "grad_norm": 1.388473391532898,
      "learning_rate": 1.8893499308437068e-05,
      "loss": 2.2292,
      "step": 2250
    },
    {
      "epoch": 1.9082426127527217,
      "grad_norm": 1.4014679193496704,
      "learning_rate": 1.8201936376210234e-05,
      "loss": 2.2222,
      "step": 2300
    },
    {
      "epoch": 1.9497148781752203,
      "grad_norm": 1.512784481048584,
      "learning_rate": 1.7510373443983402e-05,
      "loss": 2.2298,
      "step": 2350
    },
    {
      "epoch": 1.991187143597719,
      "grad_norm": 1.5431559085845947,
      "learning_rate": 1.681881051175657e-05,
      "loss": 2.1588,
      "step": 2400
    },
    {
      "epoch": 1.9994815966822188,
      "eval_loss": 2.205855131149292,
      "eval_runtime": 51.2583,
      "eval_samples_per_second": 41.827,
      "eval_steps_per_second": 5.228,
      "step": 2410
    },
    {
      "epoch": 2.033177812337999,
      "grad_norm": 1.3046371936798096,
      "learning_rate": 1.612724757952974e-05,
      "loss": 2.2775,
      "step": 2450
    },
    {
      "epoch": 2.0746500777604977,
      "grad_norm": 1.4321061372756958,
      "learning_rate": 1.5435684647302905e-05,
      "loss": 2.2191,
      "step": 2500
    },
    {
      "epoch": 2.1161223431829965,
      "grad_norm": 1.8020933866500854,
      "learning_rate": 1.4744121715076074e-05,
      "loss": 2.2735,
      "step": 2550
    },
    {
      "epoch": 2.157594608605495,
      "grad_norm": 1.6781941652297974,
      "learning_rate": 1.405255878284924e-05,
      "loss": 2.2086,
      "step": 2600
    },
    {
      "epoch": 2.1990668740279937,
      "grad_norm": 1.6410363912582397,
      "learning_rate": 1.3360995850622406e-05,
      "loss": 2.1901,
      "step": 2650
    },
    {
      "epoch": 2.2405391394504925,
      "grad_norm": 1.545403242111206,
      "learning_rate": 1.2669432918395573e-05,
      "loss": 2.2026,
      "step": 2700
    },
    {
      "epoch": 2.2820114048729914,
      "grad_norm": 1.5095977783203125,
      "learning_rate": 1.1977869986168742e-05,
      "loss": 2.1664,
      "step": 2750
    },
    {
      "epoch": 2.3234836702954897,
      "grad_norm": 1.6273887157440186,
      "learning_rate": 1.1286307053941909e-05,
      "loss": 2.2054,
      "step": 2800
    },
    {
      "epoch": 2.3649559357179886,
      "grad_norm": 1.6894950866699219,
      "learning_rate": 1.0594744121715076e-05,
      "loss": 2.1945,
      "step": 2850
    },
    {
      "epoch": 2.4064282011404874,
      "grad_norm": 1.4072587490081787,
      "learning_rate": 9.903181189488243e-06,
      "loss": 2.1814,
      "step": 2900
    },
    {
      "epoch": 2.447900466562986,
      "grad_norm": 1.9132063388824463,
      "learning_rate": 9.211618257261412e-06,
      "loss": 2.2188,
      "step": 2950
    },
    {
      "epoch": 2.4893727319854846,
      "grad_norm": 1.6249439716339111,
      "learning_rate": 8.520055325034579e-06,
      "loss": 2.1954,
      "step": 3000
    },
    {
      "epoch": 2.5308449974079834,
      "grad_norm": 1.5324418544769287,
      "learning_rate": 7.828492392807746e-06,
      "loss": 2.1739,
      "step": 3050
    },
    {
      "epoch": 2.5723172628304822,
      "grad_norm": 1.7759016752243042,
      "learning_rate": 7.136929460580913e-06,
      "loss": 2.1908,
      "step": 3100
    },
    {
      "epoch": 2.6137895282529806,
      "grad_norm": 1.6633018255233765,
      "learning_rate": 6.445366528354081e-06,
      "loss": 2.1916,
      "step": 3150
    },
    {
      "epoch": 2.6552617936754794,
      "grad_norm": 1.563299536705017,
      "learning_rate": 5.753803596127248e-06,
      "loss": 2.1837,
      "step": 3200
    },
    {
      "epoch": 2.6967340590979783,
      "grad_norm": 1.6597843170166016,
      "learning_rate": 5.062240663900415e-06,
      "loss": 2.169,
      "step": 3250
    },
    {
      "epoch": 2.738206324520477,
      "grad_norm": 1.3280459642410278,
      "learning_rate": 4.370677731673582e-06,
      "loss": 2.1854,
      "step": 3300
    },
    {
      "epoch": 2.779678589942976,
      "grad_norm": 1.618874192237854,
      "learning_rate": 3.67911479944675e-06,
      "loss": 2.1748,
      "step": 3350
    },
    {
      "epoch": 2.8211508553654743,
      "grad_norm": 1.6621004343032837,
      "learning_rate": 2.9875518672199173e-06,
      "loss": 2.1616,
      "step": 3400
    },
    {
      "epoch": 2.862623120787973,
      "grad_norm": 1.5999484062194824,
      "learning_rate": 2.2959889349930847e-06,
      "loss": 2.1576,
      "step": 3450
    },
    {
      "epoch": 2.9040953862104715,
      "grad_norm": 1.936315894126892,
      "learning_rate": 1.6044260027662516e-06,
      "loss": 2.1538,
      "step": 3500
    },
    {
      "epoch": 2.9455676516329703,
      "grad_norm": 1.6264151334762573,
      "learning_rate": 9.128630705394192e-07,
      "loss": 2.1686,
      "step": 3550
    },
    {
      "epoch": 2.987039917055469,
      "grad_norm": 1.6762439012527466,
      "learning_rate": 2.2130013831258645e-07,
      "loss": 2.1923,
      "step": 3600
    },
    {
      "epoch": 2.9994815966822186,
      "eval_loss": 2.192427396774292,
      "eval_runtime": 51.2162,
      "eval_samples_per_second": 41.862,
      "eval_steps_per_second": 5.233,
      "step": 3615
    }
  ],
  "logging_steps": 50,
  "max_steps": 3615,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5396179197158400.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
