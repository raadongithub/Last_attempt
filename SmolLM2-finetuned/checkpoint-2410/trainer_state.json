{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9994815966822188,
  "eval_steps": 500,
  "global_step": 2410,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.041472265422498704,
      "grad_norm": 0.5809592008590698,
      "learning_rate": 4.932226832641771e-05,
      "loss": 2.8854,
      "step": 50
    },
    {
      "epoch": 0.08294453084499741,
      "grad_norm": 0.6697035431861877,
      "learning_rate": 4.8630705394190874e-05,
      "loss": 2.6279,
      "step": 100
    },
    {
      "epoch": 0.12441679626749612,
      "grad_norm": 0.6377636194229126,
      "learning_rate": 4.793914246196404e-05,
      "loss": 2.5358,
      "step": 150
    },
    {
      "epoch": 0.16588906168999482,
      "grad_norm": 0.9169598817825317,
      "learning_rate": 4.7247579529737204e-05,
      "loss": 2.4202,
      "step": 200
    },
    {
      "epoch": 0.20736132711249353,
      "grad_norm": 0.9329835772514343,
      "learning_rate": 4.655601659751038e-05,
      "loss": 2.4119,
      "step": 250
    },
    {
      "epoch": 0.24883359253499224,
      "grad_norm": 0.8183119297027588,
      "learning_rate": 4.586445366528354e-05,
      "loss": 2.3695,
      "step": 300
    },
    {
      "epoch": 0.2903058579574909,
      "grad_norm": 0.8457039594650269,
      "learning_rate": 4.517289073305671e-05,
      "loss": 2.3731,
      "step": 350
    },
    {
      "epoch": 0.33177812337998963,
      "grad_norm": 1.0700610876083374,
      "learning_rate": 4.448132780082987e-05,
      "loss": 2.366,
      "step": 400
    },
    {
      "epoch": 0.37325038880248834,
      "grad_norm": 1.0347192287445068,
      "learning_rate": 4.378976486860305e-05,
      "loss": 2.3345,
      "step": 450
    },
    {
      "epoch": 0.41472265422498705,
      "grad_norm": 1.1043345928192139,
      "learning_rate": 4.309820193637622e-05,
      "loss": 2.341,
      "step": 500
    },
    {
      "epoch": 0.45619491964748576,
      "grad_norm": 1.0495500564575195,
      "learning_rate": 4.240663900414938e-05,
      "loss": 2.32,
      "step": 550
    },
    {
      "epoch": 0.4976671850699845,
      "grad_norm": 1.0272525548934937,
      "learning_rate": 4.171507607192255e-05,
      "loss": 2.3282,
      "step": 600
    },
    {
      "epoch": 0.5391394504924831,
      "grad_norm": 1.078452706336975,
      "learning_rate": 4.102351313969571e-05,
      "loss": 2.2758,
      "step": 650
    },
    {
      "epoch": 0.5806117159149818,
      "grad_norm": 1.0846186876296997,
      "learning_rate": 4.0331950207468885e-05,
      "loss": 2.284,
      "step": 700
    },
    {
      "epoch": 0.6220839813374806,
      "grad_norm": 1.0267579555511475,
      "learning_rate": 3.964038727524205e-05,
      "loss": 2.3028,
      "step": 750
    },
    {
      "epoch": 0.6635562467599793,
      "grad_norm": 1.206338882446289,
      "learning_rate": 3.8948824343015216e-05,
      "loss": 2.3125,
      "step": 800
    },
    {
      "epoch": 0.705028512182478,
      "grad_norm": 1.2561907768249512,
      "learning_rate": 3.825726141078838e-05,
      "loss": 2.3011,
      "step": 850
    },
    {
      "epoch": 0.7465007776049767,
      "grad_norm": 1.1792067289352417,
      "learning_rate": 3.756569847856155e-05,
      "loss": 2.3033,
      "step": 900
    },
    {
      "epoch": 0.7879730430274754,
      "grad_norm": 1.3312841653823853,
      "learning_rate": 3.687413554633472e-05,
      "loss": 2.2747,
      "step": 950
    },
    {
      "epoch": 0.8294453084499741,
      "grad_norm": 1.1686315536499023,
      "learning_rate": 3.6182572614107884e-05,
      "loss": 2.2762,
      "step": 1000
    },
    {
      "epoch": 0.8709175738724728,
      "grad_norm": 1.309641718864441,
      "learning_rate": 3.549100968188105e-05,
      "loss": 2.278,
      "step": 1050
    },
    {
      "epoch": 0.9123898392949715,
      "grad_norm": 1.2368624210357666,
      "learning_rate": 3.479944674965422e-05,
      "loss": 2.2756,
      "step": 1100
    },
    {
      "epoch": 0.9538621047174702,
      "grad_norm": 1.2262755632400513,
      "learning_rate": 3.410788381742739e-05,
      "loss": 2.2807,
      "step": 1150
    },
    {
      "epoch": 0.995334370139969,
      "grad_norm": 1.140794038772583,
      "learning_rate": 3.341632088520055e-05,
      "loss": 2.287,
      "step": 1200
    },
    {
      "epoch": 0.9994815966822188,
      "eval_loss": 2.254227876663208,
      "eval_runtime": 51.0993,
      "eval_samples_per_second": 41.958,
      "eval_steps_per_second": 5.245,
      "step": 1205
    },
    {
      "epoch": 1.0373250388802489,
      "grad_norm": 1.4560914039611816,
      "learning_rate": 3.272475795297372e-05,
      "loss": 2.2804,
      "step": 1250
    },
    {
      "epoch": 1.0787973043027475,
      "grad_norm": 0.9947916269302368,
      "learning_rate": 3.203319502074689e-05,
      "loss": 2.2716,
      "step": 1300
    },
    {
      "epoch": 1.1202695697252463,
      "grad_norm": 1.5184032917022705,
      "learning_rate": 3.134163208852006e-05,
      "loss": 2.2481,
      "step": 1350
    },
    {
      "epoch": 1.1617418351477449,
      "grad_norm": 1.2594051361083984,
      "learning_rate": 3.065006915629323e-05,
      "loss": 2.2167,
      "step": 1400
    },
    {
      "epoch": 1.2032141005702437,
      "grad_norm": 1.331413984298706,
      "learning_rate": 2.995850622406639e-05,
      "loss": 2.2515,
      "step": 1450
    },
    {
      "epoch": 1.2446863659927423,
      "grad_norm": 1.3618131875991821,
      "learning_rate": 2.926694329183956e-05,
      "loss": 2.2303,
      "step": 1500
    },
    {
      "epoch": 1.2861586314152411,
      "grad_norm": 1.5077323913574219,
      "learning_rate": 2.8575380359612723e-05,
      "loss": 2.2359,
      "step": 1550
    },
    {
      "epoch": 1.3276308968377397,
      "grad_norm": 1.498534083366394,
      "learning_rate": 2.7883817427385895e-05,
      "loss": 2.2519,
      "step": 1600
    },
    {
      "epoch": 1.3691031622602385,
      "grad_norm": 1.7218949794769287,
      "learning_rate": 2.7192254495159057e-05,
      "loss": 2.2022,
      "step": 1650
    },
    {
      "epoch": 1.4105754276827371,
      "grad_norm": 1.3789340257644653,
      "learning_rate": 2.650069156293223e-05,
      "loss": 2.2096,
      "step": 1700
    },
    {
      "epoch": 1.4520476931052357,
      "grad_norm": 1.4332889318466187,
      "learning_rate": 2.5809128630705398e-05,
      "loss": 2.2278,
      "step": 1750
    },
    {
      "epoch": 1.4935199585277346,
      "grad_norm": 1.4190764427185059,
      "learning_rate": 2.5117565698478563e-05,
      "loss": 2.2562,
      "step": 1800
    },
    {
      "epoch": 1.5349922239502334,
      "grad_norm": 1.5007836818695068,
      "learning_rate": 2.442600276625173e-05,
      "loss": 2.1757,
      "step": 1850
    },
    {
      "epoch": 1.576464489372732,
      "grad_norm": 1.6432585716247559,
      "learning_rate": 2.3734439834024897e-05,
      "loss": 2.2144,
      "step": 1900
    },
    {
      "epoch": 1.6179367547952306,
      "grad_norm": 1.3184257745742798,
      "learning_rate": 2.3042876901798063e-05,
      "loss": 2.2582,
      "step": 1950
    },
    {
      "epoch": 1.6594090202177294,
      "grad_norm": 1.8165347576141357,
      "learning_rate": 2.2351313969571235e-05,
      "loss": 2.2218,
      "step": 2000
    },
    {
      "epoch": 1.7008812856402282,
      "grad_norm": 1.4688024520874023,
      "learning_rate": 2.16597510373444e-05,
      "loss": 2.2333,
      "step": 2050
    },
    {
      "epoch": 1.7423535510627268,
      "grad_norm": 1.5979900360107422,
      "learning_rate": 2.096818810511757e-05,
      "loss": 2.1863,
      "step": 2100
    },
    {
      "epoch": 1.7838258164852254,
      "grad_norm": 1.6547327041625977,
      "learning_rate": 2.0276625172890734e-05,
      "loss": 2.2293,
      "step": 2150
    },
    {
      "epoch": 1.8252980819077242,
      "grad_norm": 1.3464412689208984,
      "learning_rate": 1.95850622406639e-05,
      "loss": 2.2215,
      "step": 2200
    },
    {
      "epoch": 1.866770347330223,
      "grad_norm": 1.388473391532898,
      "learning_rate": 1.8893499308437068e-05,
      "loss": 2.2292,
      "step": 2250
    },
    {
      "epoch": 1.9082426127527217,
      "grad_norm": 1.4014679193496704,
      "learning_rate": 1.8201936376210234e-05,
      "loss": 2.2222,
      "step": 2300
    },
    {
      "epoch": 1.9497148781752203,
      "grad_norm": 1.512784481048584,
      "learning_rate": 1.7510373443983402e-05,
      "loss": 2.2298,
      "step": 2350
    },
    {
      "epoch": 1.991187143597719,
      "grad_norm": 1.5431559085845947,
      "learning_rate": 1.681881051175657e-05,
      "loss": 2.1588,
      "step": 2400
    },
    {
      "epoch": 1.9994815966822188,
      "eval_loss": 2.205855131149292,
      "eval_runtime": 51.2583,
      "eval_samples_per_second": 41.827,
      "eval_steps_per_second": 5.228,
      "step": 2410
    }
  ],
  "logging_steps": 50,
  "max_steps": 3615,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3597112487712000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
